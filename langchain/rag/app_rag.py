"""RAG (Retrieval-Augmented Generation) with LangChain, pgvector, and OpenAI. --> app_rag"""

import os
from typing import List

from dotenv import load_dotenv
from langchain_core.documents import Document
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import Runnable, RunnablePassthrough
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_postgres import PGVector

# Load environment variables
load_dotenv()


def main() -> None:
    """Main function demonstrating RAG with LangChain, pgvector, and OpenAI."""
    print("=" * 60)
    print("RAG Demo: LangChain + pgvector + OpenAI")
    print("=" * 60)

    # Database connection parameters
    postgres_user = os.getenv("PGVECTOR_USER", "langchain")
    postgres_password = os.getenv("PGVECTOR_PASSWORD", "langchain")
    postgres_host = os.getenv("PGVECTOR_HOST", "localhost")
    postgres_port = int(os.getenv("PGVECTOR_PORT", "5432"))
    postgres_db = os.getenv("PGVECTOR_DATABASE", "langchain")

    # Connection string using psycopg driver
    connection_string = (
        f"postgresql+psycopg://{postgres_user}:{postgres_password}"
        f"@{postgres_host}:{postgres_port}/{postgres_db}"
    )

    # Use OpenAI embeddings
    print("\nInitializing OpenAI embeddings...")
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

    # Collection name
    collection_name = "rag_collection"

    print("\nConnecting to PostgreSQL with pgvector...")
    print(f"Connection string: {connection_string.split('@')[0]}@...")

    try:
        # Initialize vector store
        print(f"Creating vector store (collection: {collection_name})...")
        store = PGVector(
            connection=connection_string,
            embeddings=embeddings,
            collection_name=collection_name,
        )
        print("âœ“ Successfully connected to pgvector!")

        # Add documents (í•œêµ­ì–´)
        documents: List[Document] = [
            Document(
                page_content="LangChainì€ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì„ êµ¬ì¶•í•˜ê¸° ìœ„í•œ ê°•ë ¥í•œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.",
                metadata={"source": "demo"},
            ),
            Document(
                page_content="RAGëŠ” Retrieval-Augmented Generationì˜ ì•½ìë¡œ, ê²€ìƒ‰ê³¼ ìƒì„±ì„ ê²°í•©í•œ ê¸°ìˆ ì…ë‹ˆë‹¤.",
                metadata={"source": "demo"},
            ),
            Document(
                page_content="pgvectorëŠ” PostgreSQLì—ì„œ ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” í™•ì¥ì…ë‹ˆë‹¤.",
                metadata={"source": "demo"},
            ),
            Document(
                page_content="OpenAIëŠ” GPT ëª¨ë¸ì„ ì œê³µí•˜ëŠ” ì¸ê³µì§€ëŠ¥ ì—°êµ¬ ê¸°ì—…ì…ë‹ˆë‹¤.",
                metadata={"source": "demo"},
            ),
            Document(
                page_content="ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ëŠ” ì„ë² ë”©ì„ ì €ì¥í•˜ê³  ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.",
                metadata={"source": "demo"},
            ),
        ]

        print(f"\nAdding {len(documents)} documents to vector store...")
        store.add_documents(documents)
        print("âœ“ Documents added successfully!")

        # Initialize OpenAI LLM
        print("\nInitializing OpenAI LLM (gpt-3.5-turbo)...")
        llm = ChatOpenAI(
            model="gpt-3.5-turbo",
            temperature=0.7,
        )
        print("âœ“ OpenAI LLM initialized!")

        # Create RAG prompt template (í•œêµ­ì–´)
        template = """ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.

ì»¨í…ìŠ¤íŠ¸:
{context}

ì§ˆë¬¸: {question}

ë‹µë³€:"""

        prompt = ChatPromptTemplate.from_template(template)

        # Create RAG chain
        def format_docs(docs: List[Document]) -> str:
            return "\n\n".join(doc.page_content for doc in docs)

        retriever = store.as_retriever(search_kwargs={"k": 2})

        rag_chain: Runnable = (
            {"context": retriever | format_docs, "question": RunnablePassthrough()}
            | prompt
            | llm
            | StrOutputParser()
        )

        # Test RAG with queries (í•œêµ­ì–´)
        queries = [
            "LangChainì´ ë­ì•¼?",
            "RAGê°€ ë¬´ì—‡ì¸ê°€ìš”?",
            "pgvectorì˜ ì—­í• ì€?",
        ]

        print("\n" + "=" * 60)
        print("RAG Query Results")
        print("=" * 60)

        for query in queries:
            print(f"\nğŸ“ Question: {query}")
            print("-" * 60)

            # Get retrieved documents
            retrieved_docs = store.similarity_search(query, k=2)
            print("ğŸ“š Retrieved Documents:")
            for i, doc in enumerate(retrieved_docs, 1):
                print(f"  {i}. {doc.page_content[:80]}...")

            # Get RAG answer
            print("\nğŸ¤– RAG Answer:")
            answer = rag_chain.invoke(query)
            print(f"  {answer}")
            print()

        print("=" * 60)
        print("âœ“ RAG Demo completed successfully!")
        print("=" * 60)

    except Exception as e:
        print(f"âœ— Error: {e}")
        import traceback

        traceback.print_exc()
        raise


if __name__ == "__main__":
    main()

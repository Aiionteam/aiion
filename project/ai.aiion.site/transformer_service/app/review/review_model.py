"""
Review Sentiment Model
ì˜í™” ë¦¬ë·° ê°ì„± ë¶„ì„ ëª¨ë¸ í´ë˜ìŠ¤
"""

import torch
import torch.nn as nn
from pathlib import Path
from typing import Optional
from icecream import ic

try:
    from transformers import (
        AutoTokenizer,
        AutoModel,
        AutoConfig,
    )
    TORCH_AVAILABLE = True
    DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
except ImportError:
    TORCH_AVAILABLE = False
    DEVICE = None
    ic("ê²½ê³ : torch ë˜ëŠ” transformersê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")


class ReviewSentimentClassifier(nn.Module):
    """KoELECTRA ê¸°ë°˜ ì˜í™” ë¦¬ë·° ê°ì„± ë¶„ë¥˜ ëª¨ë¸"""
    
    def __init__(
        self,
        model_name: str = "koelectro_v3_base",
        num_labels: int = 2,  # ê¸ì •/ë¶€ì • 2-class
        dropout_rate: float = 0.3,
        hidden_size: Optional[int] = None
    ):
        """
        ì´ˆê¸°í™”
        
        Args:
            model_name: KoELECTRA ëª¨ë¸ ê²½ë¡œ ë˜ëŠ” ì´ë¦„
            num_labels: í´ë˜ìŠ¤ ìˆ˜ (2: ê¸ì •/ë¶€ì •)
            dropout_rate: Dropout ë¹„ìœ¨
            hidden_size: ì¤‘ê°„ hidden layer í¬ê¸°
        """
        super().__init__()
        if not TORCH_AVAILABLE:
            raise ImportError("torchì™€ transformersê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        self.num_labels = num_labels
        
        # ëª¨ë¸ ê²½ë¡œ ì°¾ê¸°
        model_path = self._find_model_path(model_name)
        
        if model_path.exists() and (model_path / "config.json").exists():
            # ë¡œì»¬ ëª¨ë¸ ë¡œë“œ
            ic(f"âœ… ë¡œì»¬ ëª¨ë¸ ë¡œë“œ: {model_path}")
            self.config = AutoConfig.from_pretrained(str(model_path))
            self.bert = AutoModel.from_pretrained(str(model_path))
        else:
            # HuggingFace ëª¨ë¸ ë¡œë“œ
            ic(f"ğŸŒ HuggingFace ëª¨ë¸ ë¡œë“œ: {model_name}")
            self.config = AutoConfig.from_pretrained(model_name)
            self.bert = AutoModel.from_pretrained(model_name)
        
        self.dropout = nn.Dropout(dropout_rate)
        
        # ë¶„ë¥˜ í—¤ë“œ
        if hidden_size:
            self.classifier = nn.Sequential(
                nn.Linear(self.config.hidden_size, hidden_size),
                nn.ReLU(),
                nn.Dropout(dropout_rate),
                nn.Linear(hidden_size, num_labels)
            )
        else:
            self.classifier = nn.Linear(self.config.hidden_size, num_labels)
        
        self.model_name = model_name
        ic(f"ReviewSentimentClassifier ì´ˆê¸°í™” ì™„ë£Œ: {num_labels}-class")
    
    def _find_model_path(self, model_name: str) -> Path:
        """KoELECTRA ëª¨ë¸ ê²½ë¡œ ì°¾ê¸°"""
        model_path_str = str(model_name)
        
        # ì ˆëŒ€ ê²½ë¡œê°€ ì•„ë‹ˆë©´ ì°¾ê¸°
        if not Path(model_path_str).is_absolute():
            # 1. Docker í™˜ê²½: /app/koelectro_v3_base
            docker_path = Path("/app/koelectro_v3_base")
            if docker_path.exists() and (docker_path / "config.json").exists():
                return docker_path
            
            # 2. ê³µí†µ ëª¨ë¸ ì €ì¥ì†Œ: models/koelectra
            # transformer_service/appì´ ë£¨íŠ¸
            current_dir = Path(__file__).parent  # review
            app_dir = current_dir.parent  # app
            service_dir = app_dir.parent  # transformer_service
            ai_dir = service_dir.parent  # ai.aiion.site
            common_model_path = ai_dir / "models" / "koelectra"
            if common_model_path.exists() and (common_model_path / "config.json").exists():
                return common_model_path
        
        return Path(model_path_str)
    
    def forward(
        self,
        input_ids: torch.Tensor,
        attention_mask: torch.Tensor,
        token_type_ids: Optional[torch.Tensor] = None
    ):
        """
        ìˆœì „íŒŒ
        
        Args:
            input_ids: í† í° ID
            attention_mask: Attention mask
            token_type_ids: Token type IDs
            
        Returns:
            logits: ê° í´ë˜ìŠ¤ì— ëŒ€í•œ ë¡œì§“
        """
        outputs = self.bert(
            input_ids=input_ids,
            attention_mask=attention_mask,
            token_type_ids=token_type_ids
        )
        
        # [CLS] í† í°ì˜ hidden state ì¶”ì¶œ
        pooled_output = outputs.last_hidden_state[:, 0, :]
        
        # Dropout ë° ë¶„ë¥˜
        pooled_output = self.dropout(pooled_output)
        logits = self.classifier(pooled_output)
        
        return logits
    
    def freeze_bert_layers(self, num_layers_to_freeze: int = 8):
        """BERT í•˜ìœ„ ë ˆì´ì–´ ë™ê²°"""
        for param in self.bert.embeddings.parameters():
            param.requires_grad = False
        
        for i in range(num_layers_to_freeze):
            if i < len(self.bert.encoder.layer):
                for param in self.bert.encoder.layer[i].parameters():
                    param.requires_grad = False
        
        ic(f"BERT í•˜ìœ„ {num_layers_to_freeze}ê°œ ë ˆì´ì–´ ë™ê²° ì™„ë£Œ")


class ReviewSentimentDLModel:
    """ì˜í™” ë¦¬ë·° ê°ì„± ë¶„ì„ DL ëª¨ë¸ ë˜í¼ í´ë˜ìŠ¤"""
    
    def __init__(
        self,
        model_name: str = "koelectro_v3_base",
        num_labels: int = 2,
        max_length: int = 512,
        device: Optional[torch.device] = None
    ):
        """
        ì´ˆê¸°í™”
        
        Args:
            model_name: KoELECTRA ëª¨ë¸ ì´ë¦„ ë˜ëŠ” ê²½ë¡œ
            num_labels: í´ë˜ìŠ¤ ìˆ˜ (2: ê¸ì •/ë¶€ì •)
            max_length: ìµœëŒ€ í† í° ê¸¸ì´
            device: ë””ë°”ì´ìŠ¤
        """
        if not TORCH_AVAILABLE:
            raise ImportError("torchì™€ transformersê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        self.model_name = model_name
        self.num_labels = num_labels
        self.max_length = max_length
        
        if device is None:
            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        else:
            self.device = device
        
        # í† í¬ë‚˜ì´ì € ë¡œë“œ
        model_path = self._find_model_path(model_name)
        if model_path.exists() and (model_path / "config.json").exists():
            ic(f"âœ… ë¡œì»¬ í† í¬ë‚˜ì´ì € ë¡œë“œ: {model_path}")
            self.tokenizer = AutoTokenizer.from_pretrained(str(model_path))
        else:
            ic(f"ğŸŒ HuggingFace í† í¬ë‚˜ì´ì € ë¡œë“œ: {model_name}")
            self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        self.model = None
        
        ic(f"ReviewSentimentDLModel ì´ˆê¸°í™” ì™„ë£Œ: device={self.device}")
    
    def _find_model_path(self, model_name: str) -> Path:
        """KoELECTRA ëª¨ë¸ ê²½ë¡œ ì°¾ê¸°"""
        model_path_str = str(model_name)
        
        if not Path(model_path_str).is_absolute():
            # 1. Docker í™˜ê²½
            docker_path = Path("/app/koelectro_v3_base")
            if docker_path.exists() and (docker_path / "config.json").exists():
                return docker_path
            
            # 2. ê³µí†µ ëª¨ë¸ ì €ì¥ì†Œ
            current_dir = Path(__file__).parent  # review
            app_dir = current_dir.parent  # app
            service_dir = app_dir.parent  # transformer_service
            ai_dir = service_dir.parent  # ai.aiion.site
            common_model_path = ai_dir / "models" / "koelectra"
            if common_model_path.exists() and (common_model_path / "config.json").exists():
                return common_model_path
        
        return Path(model_path_str)
    
    def create_model(
        self,
        dropout_rate: float = 0.3,
        hidden_size: Optional[int] = None
    ):
        """ëª¨ë¸ ìƒì„±"""
        self.model = ReviewSentimentClassifier(
            model_name=self.model_name,
            num_labels=self.num_labels,
            dropout_rate=dropout_rate,
            hidden_size=hidden_size
        )
        self.model.to(self.device)
        ic(f"ëª¨ë¸ ìƒì„± ì™„ë£Œ: {self.model_name}")
    
    def __repr__(self) -> str:
        """ë¬¸ìì—´ í‘œí˜„"""
        return f"ReviewSentimentDLModel(model_name={self.model_name}, device={self.device})"


"""
Diary Emotion Service
ì¼ê¸° ê°ì • ë¶„ë¥˜ ë”¥ëŸ¬ë‹ ì„œë¹„ìŠ¤ (DL ì „ìš©)
"""

import sys
from pathlib import Path
from typing import List, Dict, Optional, Any
import pandas as pd
import numpy as np
import pickle
from datetime import datetime
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

# ic ë¨¼ì € ì •ì˜
try:
    from icecream import ic  # type: ignore
except ImportError:
    def ic(*args, **kwargs):
        if args or kwargs:
            print(*args, **kwargs)
        return args[0] if args else None

# ê³µí†µ ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€ (business/diary_service/appì´ ë£¨íŠ¸)
sys.path.insert(0, str(Path(__file__).parent.parent))

# DL ì „ìš© import
from diary_emotion.diary_emotion_dataset import DiaryEmotionDataSet
from diary_emotion.diary_emotion_method import DiaryEmotionMethod
from diary_emotion.diary_emotion_model import DiaryEmotionDLModel, TORCH_AVAILABLE
from diary_emotion.diary_emotion_dl_trainer import DiaryEmotionDLTrainer

DL_AVAILABLE = TORCH_AVAILABLE
if not DL_AVAILABLE:
    raise ImportError("ë”¥ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬(PyTorch)ê°€ í•„ìš”í•©ë‹ˆë‹¤.")


class DiaryEmotionService:
    """ì¼ê¸° ê°ì • ë¶„ë¥˜ ë”¥ëŸ¬ë‹ ì„œë¹„ìŠ¤ (DL ì „ìš©)"""
    
    def __init__(
        self,
        csv_file_path: Optional[Path] = None,
        dl_model_name: str = "koelectro_v3_base"  # ë¡œì»¬ KoELECTRA v3 base ëª¨ë¸ ì‚¬ìš©
    ):
        """
        ì´ˆê¸°í™” (DL ì „ìš©)
        
        Args:
            csv_file_path: CSV íŒŒì¼ ê²½ë¡œ
            dl_model_name: ë”¥ëŸ¬ë‹ ëª¨ë¸ ì´ë¦„ (ê¸°ë³¸: koelectro_v3_base)
        """
        self.dataset = DiaryEmotionDataSet()
        self.method = DiaryEmotionMethod()  # ì „ì²˜ë¦¬ ë©”ì„œë“œ í´ë˜ìŠ¤
        
        # DL ì „ìš© ì„¤ì •
        self.model_type = "dl"
        self.dl_model_name = dl_model_name
        
        # CSV íŒŒì¼ ê²½ë¡œ (diary_copers.csv ì‚¬ìš©)
        if csv_file_path is None:
            self.csv_file_path = Path(__file__).parent / "data" / "diary_copers.csv"
        else:
            self.csv_file_path = csv_file_path
        self.df: Optional[pd.DataFrame] = None
        
        # ëª¨ë¸ ì €ì¥ ê²½ë¡œ (ì¤‘ì•™ ì €ì¥ì†Œ: models/trained_models/diary_emotion/)
        # Docker í™˜ê²½: /app/models/trained_models/diary_emotion
        # ë¡œì»¬ í™˜ê²½: ai.aiion.site/models/trained_models/diary_emotion
        docker_model_dir = Path("/app/models/trained_models/diary_emotion")
        if docker_model_dir.exists():
            self.model_dir = docker_model_dir
            ic(f"âœ… Docker ì¤‘ì•™ ì €ì¥ì†Œ ì‚¬ìš©: {self.model_dir}")
        else:
            # ë¡œì»¬ í™˜ê²½: ìƒëŒ€ ê²½ë¡œë¡œ ì°¾ê¸°
            current_dir = Path(__file__).parent  # diary_emotion
            app_dir = current_dir.parent  # app
            service_dir = app_dir.parent  # diary_service
            business_dir = service_dir.parent  # business
            ai_dir = business_dir.parent  # ai.aiion.site
            local_model_dir = ai_dir / "models" / "trained_models" / "diary_emotion"
            if local_model_dir.exists():
                self.model_dir = local_model_dir
                ic(f"âœ… ë¡œì»¬ ì¤‘ì•™ ì €ì¥ì†Œ ì‚¬ìš©: {self.model_dir}")
            else:
                # í•˜ìœ„ í˜¸í™˜ì„±: ê¸°ì¡´ ìœ„ì¹˜
                self.model_dir = Path(__file__).parent / "models"
                self.model_dir.mkdir(exist_ok=True)
                ic(f"âš ï¸ ì¤‘ì•™ ì €ì¥ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ì¡´ ìœ„ì¹˜ ì‚¬ìš©: {self.model_dir}")
        
        # DL ëª¨ë¸ íŒŒì¼
        self.dl_model_file = self.model_dir / "diary_emotion_dl_model.pt"
        self.dl_metadata_file = self.model_dir / "diary_emotion_dl_metadata.pkl"
        
        # ë”¥ëŸ¬ë‹ ëª¨ë¸ ë° íŠ¸ë ˆì´ë„ˆ
        self.dl_model_obj: Optional[DiaryEmotionDLModel] = None
        self.dl_trainer: Optional[DiaryEmotionDLTrainer] = None
        
        ic("DiaryEmotionService ì´ˆê¸°í™”: DL ì „ìš© ëª¨ë“œ")
        
        # DL ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸
        if not DL_AVAILABLE:
            raise RuntimeError("ë”¥ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. PyTorchì™€ transformersë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”.")
        
        # ë”¥ëŸ¬ë‹ ëª¨ë¸ ì´ˆê¸°í™”
        self._init_dl_model()
        
        # ì„œë¹„ìŠ¤ ì‹œì‘ ì‹œ ëª¨ë¸ ìë™ ë¡œë“œ ì‹œë„
        self._try_load_model()
    
    def _init_dl_model(self):
        """ë”¥ëŸ¬ë‹ ëª¨ë¸ ì´ˆê¸°í™” (DL ì „ìš©)"""
        try:
            # ê°ì • í´ë˜ìŠ¤ ìˆ˜ ë™ì  ê³„ì‚° (ë°ì´í„° ë¡œë“œ í›„)
            if self.df is not None and 'emotion' in self.df.columns:
                unique_emotions = self.df['emotion'].unique()
                num_labels = len(unique_emotions)
                ic(f"ê°ì • í´ë˜ìŠ¤ ìˆ˜: {num_labels} (ê°ì • ê°’: {sorted(unique_emotions)})")
            else:
                num_labels = 15  # ê¸°ë³¸ê°’ (ë¡œê·¸ì—ì„œ í™•ì¸ëœ í´ë˜ìŠ¤ ìˆ˜)
                ic(f"ë°ì´í„° ë¯¸ë¡œë“œ, ê¸°ë³¸ ê°ì • í´ë˜ìŠ¤ ìˆ˜ ì‚¬ìš©: {num_labels}")
            
            self.dl_model_obj = DiaryEmotionDLModel(
                model_name=self.dl_model_name,
                num_labels=num_labels,  # ë™ì ìœ¼ë¡œ ê³„ì‚°ëœ ê°ì • í´ë˜ìŠ¤ ìˆ˜
                max_length=512
            )
            ic(f"âœ… DL ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ: {self.dl_model_name}")
        except Exception as e:
            ic(f"âŒ DL ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise RuntimeError(f"DL ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def preprocess(self):
        """ë°ì´í„° ì „ì²˜ë¦¬"""
        ic("ğŸ˜ğŸ˜ ì „ì²˜ë¦¬ ì‹œì‘")
        
        try:
            # CSV íŒŒì¼ ë¡œë“œ (method ì‚¬ìš©)
            self.df = self.method.load_csv(self.csv_file_path)
            ic(f"CSV íŒŒì¼ ê²½ë¡œ: {self.csv_file_path}")
            ic(f"CSV íŒŒì¼ ì¡´ì¬ ì—¬ë¶€: {self.csv_file_path.exists()}")
            
            # ë°ì´í„° ê¸°ë³¸ ì •ë³´ í™•ì¸
            ic(f"ì»¬ëŸ¼: {list(self.df.columns)}")
            ic(f"ë°ì´í„° íƒ€ì…: {self.df.dtypes.to_dict()}")
            
            # ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (method ì‚¬ìš©)
            # text ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ text ì‚¬ìš©, ì—†ìœ¼ë©´ content ì‚¬ìš© (í•˜ìœ„ í˜¸í™˜ì„±)
            required_cols = ['text', 'emotion'] if 'text' in self.df.columns else ['content', 'emotion']
            self.df = self.method.handle_missing_values(self.df, required_cols)
            
            # ê°ì • ë¶„í¬ í™•ì¸
            emotion_dist = self.method.get_label_distribution(self.df, 'emotion')
            if emotion_dist:
                ic(f"ê°ì • ë¶„í¬: {emotion_dist}")
            
            # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (method ì‚¬ìš©)
            self.df = self.method.preprocess_text(self.df)
            
            # ê°ì • ë¼ë²¨ í™•ì¸ (15ê°œ í´ë˜ìŠ¤)
            emotion_labels_str = "0=í‰ê°€ë¶ˆê°€, 1=ê¸°ì¨, 2=ìŠ¬í””, 3=ë¶„ë…¸, 4=ë‘ë ¤ì›€, 5=í˜ì˜¤, 6=ë†€ëŒ, 7=ì‹ ë¢°, 8=ê¸°ëŒ€, 9=ë¶ˆì•ˆ, 10=ì•ˆë„, 11=í›„íšŒ, 12=ê·¸ë¦¬ì›€, 13=ê°ì‚¬, 14=ì™¸ë¡œì›€"
            ic(f"ê°ì • ë¼ë²¨: {emotion_labels_str}")
            
            ic("ğŸ˜ğŸ˜ ì „ì²˜ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            ic(f"ì „ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            raise
    
    def learning(
        self, 
        epochs: int = 3, 
        batch_size: int = 8, 
        freeze_bert_layers: int = 8,
        learning_rate: float = 2e-5,
        max_length: int = 256,
        early_stopping_patience: int = 2,
        use_amp: bool = True,
        label_smoothing: float = 0.0  # Label smoothing (0.0 = ë¹„í™œì„±í™”, 0.1 = ê¶Œì¥ê°’)
    ):
        """ëª¨ë¸ í•™ìŠµ (DL ì „ìš©)"""
        ic(f"ğŸ˜ğŸ˜ DL í•™ìŠµ ì‹œì‘")
        
        return self._learning_dl(
            epochs=epochs, 
            batch_size=batch_size, 
            freeze_bert_layers=freeze_bert_layers,
            learning_rate=learning_rate,
            max_length=max_length,
            early_stopping_patience=early_stopping_patience,
            use_amp=use_amp,
            label_smoothing=label_smoothing
        )
    
    def _learning_dl(
        self, 
        epochs: int = 3, 
        batch_size: int = 8, 
        freeze_bert_layers: int = 8,
        learning_rate: float = 2e-5,
        max_length: int = 256,
        early_stopping_patience: int = 2,
        use_amp: bool = True,
        label_smoothing: float = 0.0  # Label smoothing (0.0 = ë¹„í™œì„±í™”, 0.1 = ê¶Œì¥ê°’)
    ):
        """ë”¥ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ"""
        ic("ğŸ˜ğŸ˜ DL í•™ìŠµ ì‹œì‘")
        
        try:
            if not DL_AVAILABLE:
                raise ImportError("ë”¥ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            if self.df is None:
                raise ValueError("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. preprocess()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
            
            # ëª¨ë¸ ìƒì„±
            if self.dl_model_obj is None:
                self._init_dl_model()
            
            self.dl_model_obj.create_model(
                dropout_rate=0.3,
                hidden_size=256  # ì¤‘ê°„ ë ˆì´ì–´ ì¶”ê°€
            )
            
            # íŠ¸ë ˆì´ë„ˆ ìƒì„±
            self.dl_trainer = DiaryEmotionDLTrainer(
                model=self.dl_model_obj.model,
                tokenizer=self.dl_model_obj.tokenizer,
                device=self.dl_model_obj.device
            )
            
            # ë°ì´í„° ì¤€ë¹„
            texts = self.df['text'].tolist()
            labels = self.df['emotion'].tolist()
            
            # í•™ìŠµ/ê²€ì¦ ë¶„í• 
            train_texts, val_texts, train_labels, val_labels = train_test_split(
                texts, labels, test_size=0.2, random_state=42, stratify=labels
            )
            
            ic(f"í•™ìŠµ ë°ì´í„°: {len(train_texts)}ê°œ, ê²€ì¦ ë°ì´í„°: {len(val_texts)}ê°œ")
            
            # í•™ìŠµ (íŒŒë¼ë¯¸í„° ì „ë‹¬)
            history = self.dl_trainer.train(
                train_texts=train_texts,
                train_labels=train_labels,
                val_texts=val_texts,
                val_labels=val_labels,
                epochs=epochs,
                batch_size=batch_size,
                learning_rate=learning_rate,
                max_length=max_length,
                freeze_bert_layers=freeze_bert_layers,
                early_stopping_patience=early_stopping_patience,
                use_amp=use_amp,
                label_smoothing=label_smoothing
            )
            
            # í•™ìŠµ ë°ì´í„°ì…‹ ì €ì¥
            self.dataset.train = pd.DataFrame({
                'text': train_texts,
                'emotion': train_labels
            })
            self.dataset.test = pd.DataFrame({
                'text': val_texts,
                'emotion': val_labels
            })
            
            ic(f"ìµœì¢… ê²€ì¦ ì •í™•ë„: {history['final_val_accuracy']:.4f}")
            ic("ğŸ˜ğŸ˜ DL í•™ìŠµ ì™„ë£Œ")
            
            return history
            
        except Exception as e:
            ic(f"DL í•™ìŠµ ì˜¤ë¥˜: {e}")
            raise
    
    def evaluate(self):
        """ëª¨ë¸ í‰ê°€ (DL ì „ìš©)"""
        return self._evaluate_dl()
    
    def _evaluate_dl(self):
        """DL ëª¨ë¸ í‰ê°€"""
        ic("ğŸ˜ğŸ˜ DL í‰ê°€ ì‹œì‘")
        
        try:
            if not DL_AVAILABLE:
                raise ImportError("ë”¥ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            if self.dl_model_obj is None or self.dl_model_obj.model is None:
                raise ValueError("DL ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. learning()ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
            
            # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì´ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ì¬ìƒì„±
            if self.dataset.test is None:
                ic("í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì´ ì—†ì–´ì„œ ìë™ìœ¼ë¡œ ì¬ìƒì„±í•©ë‹ˆë‹¤...")
                if self.df is None:
                    # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì „ì²˜ë¦¬ë¶€í„° ì‹¤í–‰
                    self.preprocess()
                
                # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í•  ì¬ìƒì„± (í•™ìŠµ ì‹œì™€ ë™ì¼í•œ ë°©ì‹)
                texts = self.df['text'].tolist()
                labels = self.df['emotion'].tolist()
                
                train_texts, val_texts, train_labels, val_labels = train_test_split(
                    texts, labels, test_size=0.2, random_state=42, stratify=labels
                )
                
                # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ë§Œ ì €ì¥ (í‰ê°€ì— í•„ìš”)
                self.dataset.test = pd.DataFrame({
                    'text': val_texts,
                    'emotion': val_labels
                })
                ic(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì¬ìƒì„± ì™„ë£Œ: {len(self.dataset.test)}ê°œ")
            
            # íŠ¸ë ˆì´ë„ˆê°€ ì—†ìœ¼ë©´ ìƒì„±
            if self.dl_trainer is None:
                self.dl_trainer = DiaryEmotionDLTrainer(
                    model=self.dl_model_obj.model,
                    tokenizer=self.dl_model_obj.tokenizer,
                    device=self.dl_model_obj.device
                )
            
            # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
            test_texts = self.dataset.test['text'].tolist()
            test_labels = self.dataset.test['emotion'].tolist()
            
            # DataLoader ìƒì„±
            from torch.utils.data import DataLoader
            from diary_emotion.diary_emotion_dl_trainer import EmotionDataset
            
            test_dataset = EmotionDataset(
                texts=test_texts,
                labels=test_labels,
                tokenizer=self.dl_model_obj.tokenizer,
                max_length=256
            )
            test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)
            
            # ì†ì‹¤ í•¨ìˆ˜
            import torch.nn as nn
            criterion = nn.CrossEntropyLoss()
            
            # í‰ê°€ ì‹¤í–‰
            avg_loss, accuracy, y_true, y_pred = self.dl_trainer.evaluate(test_loader, criterion)
            
            ic(f"DL ì •í™•ë„: {accuracy:.4f}, í‰ê·  ì†ì‹¤: {avg_loss:.4f}")
            
            # ë¶„ë¥˜ ë³´ê³ ì„œ
            emotion_labels = {
                0: 'í‰ê°€ë¶ˆê°€', 1: 'ê¸°ì¨', 2: 'ìŠ¬í””', 3: 'ë¶„ë…¸', 4: 'ë‘ë ¤ì›€', 5: 'í˜ì˜¤', 6: 'ë†€ëŒ',
                7: 'ì‹ ë¢°', 8: 'ê¸°ëŒ€', 9: 'ë¶ˆì•ˆ', 10: 'ì•ˆë„', 11: 'í›„íšŒ', 12: 'ê·¸ë¦¬ì›€', 13: 'ê°ì‚¬', 14: 'ì™¸ë¡œì›€'
            }
            unique_classes = sorted(set(list(y_true) + list(y_pred)))
            target_names = [emotion_labels.get(i, f'í´ë˜ìŠ¤{i}') for i in unique_classes]
            report = classification_report(
                y_true, y_pred,
                target_names=target_names,
                output_dict=True,
                zero_division=0
            )
            ic(f"DL ë¶„ë¥˜ ë³´ê³ ì„œ:\n{classification_report(y_true, y_pred, target_names=target_names, zero_division=0)}")
            
            # í˜¼ë™ í–‰ë ¬
            cm = confusion_matrix(y_true, y_pred)
            ic(f"DL í˜¼ë™ í–‰ë ¬:\n{cm}")
            
            ic("ğŸ˜ğŸ˜ DL í‰ê°€ ì™„ë£Œ")
            
            return {
                'model_type': 'dl',
                'accuracy': float(accuracy),
                'avg_loss': float(avg_loss),
                'classification_report': report,
                'confusion_matrix': cm.tolist()
            }
            
        except Exception as e:
            ic(f"DL í‰ê°€ ì˜¤ë¥˜: {e}")
            raise
    
    def predict(self, text: str) -> Dict[str, Any]:
        """
        í…ìŠ¤íŠ¸ ê°ì • ì˜ˆì¸¡ (DL ì „ìš©)
        
        Args:
            text: ì˜ˆì¸¡í•  í…ìŠ¤íŠ¸
        
        Returns:
            ì˜ˆì¸¡ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        return self._predict_dl(text)
    def _predict_dl(self, text: str) -> Dict[str, Any]:
        """DL ëª¨ë¸ ì˜ˆì¸¡"""
        try:
            if not DL_AVAILABLE:
                raise ImportError("ë”¥ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            if self.dl_model_obj is None or self.dl_model_obj.model is None:
                raise ValueError("DL ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. learning()ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
            
            if self.dl_trainer is None:
                # íŠ¸ë ˆì´ë„ˆ ìƒì„±
                self.dl_trainer = DiaryEmotionDLTrainer(
                    model=self.dl_model_obj.model,
                    tokenizer=self.dl_model_obj.tokenizer,
                    device=self.dl_model_obj.device
                )
            
            # ì˜ˆì¸¡ ë° í™•ë¥  ê³„ì‚°
            predictions, probabilities = self.dl_trainer.predict([text], batch_size=1, return_probs=True)
            prediction = predictions[0]
            probabilities = probabilities[0]  # ì²« ë²ˆì§¸ í…ìŠ¤íŠ¸ì˜ í™•ë¥ 
            
            # ê°ì • ë¼ë²¨ ë§¤í•‘ (15ê°œ í´ë˜ìŠ¤)
            emotion_labels = {
                0: 'í‰ê°€ë¶ˆê°€', 1: 'ê¸°ì¨', 2: 'ìŠ¬í””', 3: 'ë¶„ë…¸', 4: 'ë‘ë ¤ì›€', 5: 'í˜ì˜¤', 6: 'ë†€ëŒ',
                7: 'ì‹ ë¢°', 8: 'ê¸°ëŒ€', 9: 'ë¶ˆì•ˆ', 10: 'ì•ˆë„', 11: 'í›„íšŒ', 12: 'ê·¸ë¦¬ì›€', 13: 'ê°ì‚¬', 14: 'ì™¸ë¡œì›€'
            }
            
            # ê°€ì¤‘ì¹˜ ì¡°ì • ì „ í™•ë¥  í™•ì¸ (ë””ë²„ê¹…)
            original_max_prob = float(np.max(probabilities))
            original_prediction = int(np.argmax(probabilities))
            ic(f"DL ì›ë³¸ ì˜ˆì¸¡: {emotion_labels.get(original_prediction, 'ì•Œ ìˆ˜ ì—†ìŒ')} (í™•ë¥ : {original_max_prob:.4f})")
            
            # ìƒìœ„ 3ê°œ í™•ë¥  ì¶œë ¥ (ë””ë²„ê¹…)
            top3_indices = np.argsort(probabilities)[-3:][::-1]
            ic("DL ì›ë³¸ ìƒìœ„ 3ê°œ í™•ë¥ :")
            for idx in top3_indices:
                ic(f"  {emotion_labels.get(idx, 'ì•Œ ìˆ˜ ì—†ìŒ')}: {probabilities[idx]:.4f}")
            
            # ê°ì •ë³„ ê°€ì¤‘ì¹˜ ì¡°ì • ì ìš©
            probabilities = self._apply_emotion_weights(probabilities, emotion_labels)
            
            # ìƒìœ„ 3ê°œ ê°ì •ì— í™•ë¥  ì§‘ì¤‘ (Temperature Scaling + Top-3 Boosting)
            probabilities = self._concentrate_top3_probabilities(probabilities, emotion_labels)
            
            # ê°€ì¤‘ì¹˜ ì¡°ì • í›„ ìµœì¢… ì˜ˆì¸¡ (ìµœëŒ€ í™•ë¥ )
            final_prediction = int(np.argmax(probabilities))
            emotion_label = emotion_labels.get(final_prediction, 'ì•Œ ìˆ˜ ì—†ìŒ')
            final_confidence = float(probabilities[final_prediction])
            
            ic(f"DL ìµœì¢… ì˜ˆì¸¡: {emotion_label} (í™•ë¥ : {final_confidence:.4f})")
            
            # í™•ë¥  ë”•ì…”ë„ˆë¦¬ ìƒì„±
            prob_dict = {}
            for idx, label in emotion_labels.items():
                if idx < len(probabilities):
                    prob_dict[label] = float(probabilities[idx])
            
            return {
                'emotion': final_prediction,
                'emotion_label': emotion_label,
                'probabilities': prob_dict,
                'confidence': final_confidence,
                'model_type': 'dl',
                'original_confidence': original_max_prob  # ë””ë²„ê¹…ìš©
            }
            
        except Exception as e:
            ic(f"DL ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
            raise
    
    def _concentrate_top3_probabilities(self, probabilities: np.ndarray, emotion_labels: Dict[int, str]) -> np.ndarray:
        """
        ìƒìœ„ 3ê°œ ê°ì •ì— í™•ë¥ ì„ ì§‘ì¤‘ì‹œí‚µë‹ˆë‹¤.
        
        ì „ëµ:
        1. ìƒìœ„ 3ê°œ ê°ì •ì„ ì°¾ìŠµë‹ˆë‹¤
        2. ìƒìœ„ 3ê°œì˜ í™•ë¥ ì€ ì¦í­í•˜ê³ , ë‚˜ë¨¸ì§€ëŠ” í¬ê²Œ ê°ì†Œì‹œí‚µë‹ˆë‹¤
        3. ì¬ì •ê·œí™”í•˜ì—¬ í•©ì´ 1ì´ ë˜ë„ë¡ í•©ë‹ˆë‹¤
        
        Args:
            probabilities: ê°ì •ë³„ í™•ë¥  ë°°ì—´ (15ê°œ í´ë˜ìŠ¤)
            emotion_labels: ê°ì • ë¼ë²¨ ë”•ì…”ë„ˆë¦¬
        
        Returns:
            ìƒìœ„ 3ê°œì— ì§‘ì¤‘ëœ í™•ë¥  ë°°ì—´
        """
        # ìƒìœ„ 3ê°œ ì¸ë±ìŠ¤ ì°¾ê¸°
        top3_indices = np.argsort(probabilities)[-3:][::-1]
        
        # ë””ë²„ê¹…: ìƒìœ„ 3ê°œ í™•ë¥  ì¶œë ¥
        ic("ìƒìœ„ 3ê°œ ê°ì • (ì§‘ì¤‘ ì „):")
        for idx in top3_indices:
            ic(f"  {emotion_labels.get(idx, 'ì•Œ ìˆ˜ ì—†ìŒ')}: {probabilities[idx]:.4f}")
        
        # ìƒˆë¡œìš´ í™•ë¥  ë°°ì—´ ìƒì„±
        concentrated_probs = np.zeros_like(probabilities)
        
        # ìƒìœ„ 3ê°œì˜ í™•ë¥ ì„ ì œê³±í•˜ì—¬ ì¦í­ (Temperature Scaling íš¨ê³¼)
        # ì˜ˆ: 0.1 -> 0.01, 0.2 -> 0.04, 0.3 -> 0.09
        # ê·¸ ë‹¤ìŒ ì •ê·œí™”í•˜ë©´ ë¹„ìœ¨ì´ í¬ê²Œ ë³€í•©ë‹ˆë‹¤
        for idx in top3_indices:
            # í™•ë¥ ì„ ì œê³±í•˜ì—¬ ìƒìœ„ê¶Œê³¼ í•˜ìœ„ê¶Œì˜ ì°¨ì´ë¥¼ ê·¹ëŒ€í™”
            concentrated_probs[idx] = probabilities[idx] ** 0.5  # ì œê³±ê·¼ìœ¼ë¡œ ì•½ê°„ë§Œ ì¦í­ (ë„ˆë¬´ ê·¹ë‹¨ì ì´ì§€ ì•Šê²Œ)
        
        # ë‚˜ë¨¸ì§€ëŠ” ë§¤ìš° ì‘ì€ ê°’ìœ¼ë¡œ ì„¤ì • (ì™„ì „íˆ 0ì€ ì•„ë‹˜)
        for idx in range(len(probabilities)):
            if idx not in top3_indices:
                concentrated_probs[idx] = probabilities[idx] * 0.01  # 1%ë§Œ ë‚¨ê¹€
        
        # ì •ê·œí™” (í™•ë¥  í•©ì´ 1ì´ ë˜ë„ë¡)
        concentrated_probs = concentrated_probs / (concentrated_probs.sum() + 1e-10)
        
        # ë””ë²„ê¹…: ìƒìœ„ 3ê°œ í™•ë¥  ì¶œë ¥ (ì§‘ì¤‘ í›„)
        ic("ìƒìœ„ 3ê°œ ê°ì • (ì§‘ì¤‘ í›„):")
        for idx in top3_indices:
            ic(f"  {emotion_labels.get(idx, 'ì•Œ ìˆ˜ ì—†ìŒ')}: {concentrated_probs[idx]:.4f}")
        
        return concentrated_probs
    
    def _apply_keyword_weights(self, text: str, probabilities: np.ndarray, emotion_labels: Dict[int, str]) -> np.ndarray:
        """í‚¤ì›Œë“œ ê¸°ë°˜ ê°€ì¤‘ì¹˜ë¥¼ ì ìš©í•˜ì—¬ í™•ë¥  ë³´ì •"""
        # í…ìŠ¤íŠ¸ë¥¼ ì†Œë¬¸ìë¡œ ë³€í™˜í•˜ì—¬ ê²€ìƒ‰
        text_lower = text.lower()
        
        # ê°ì •ë³„ í‚¤ì›Œë“œ ë° ê°€ì¤‘ì¹˜ ì •ì˜
        keyword_weights = {
            # í‰ê°€ë¶ˆê°€ (ì¤‘ë¦½ì  ë‚´ìš©: ê³µë¬¸ì„œ, ë©”ëª¨, ë‹¨ìˆœ ê¸°ë¡) - ë§¤ìš° ì œí•œì ìœ¼ë¡œë§Œ ì ìš©
            0: {  # í‰ê°€ë¶ˆê°€
                'keywords': [
                    # ê³µë¬¸ì„œ/ê³µë¬´ ê´€ë ¨ (êµ¬ì²´ì ì¸ ê³µì‹ ìš©ì–´ë§Œ)
                    'ê³µë¬¸', 'ê³µë¬´ë¥¼', 'ê³µë¬´ë¥¼ ë´¤ë‹¤', 'ê³µë¬´ë¥¼ ë³´ì•˜ë‹¤', 'ê³µë¬´ë¥¼ ë³¸', 'ê³µë¬´ë¥¼ ë³´ê³ ',
                    'ê³µë¬¸ì„œ', 'ê³µë¬¸ì„', 'ê³µë¬¸ì„ ì¨', 'ê³µë¬¸ì„ ë³´ëƒˆë‹¤', 'ê³µë¬¸ì„ ì‘ì„±',
                    'ë™í—Œì— ë‚˜ê°€', 'ë™í—Œì—ì„œ', 'ë™í—Œì—',
                    # ë¬¸ì„œ/ë³´ê³ ì„œ ê´€ë ¨ (ê³µì‹ì ì¸ ìš©ì–´ë§Œ)
                    'ë¬¸ì„œ ì‘ì„±', 'ë¬¸ì„œ ì‘ì„±í–ˆë‹¤', 'ë¬¸ì„œë¥¼ ì‘ì„±',
                    'ë³´ê³ ì„œ', 'ë³´ê³ ì„œë¥¼', 'ë³´ê³ ë¥¼ ì‘ì„±',
                    'ì‹œí–‰', 'ì‹œë‹¬', 'ê²°ì¬', 'ìŠ¹ì¸', 'ê²°ì¬í–ˆë‹¤', 'ìŠ¹ì¸í–ˆë‹¤',
                    'íšŒì˜ë¡', 'íšŒì˜ë¥¼ ì§„í–‰', 'íšŒì˜ë¥¼ í–ˆë‹¤',
                    'ì•ˆê±´', 'ì•ˆê±´ì„', 'ì•ˆê±´ ì²˜ë¦¬', 'ì•ˆê±´ì„ ì²˜ë¦¬',
                    # ë©”ëª¨/ê¸°ë¡ ê´€ë ¨ (ê³µì‹ì ì¸ ìš©ì–´ë§Œ)
                    'ë©”ëª¨ë¥¼ ì‘ì„±', 'ë©”ëª¨ë¥¼ í–ˆë‹¤',
                    'ê¸°ë¡ì„ ì‘ì„±', 'ê¸°ë¡ì„ í–ˆë‹¤',
                    # ê³µì‹ì /ì—…ë¬´ì  í‘œí˜„
                    'ë¶€ì„', 'ë¶€ì„í–ˆë‹¤', 'ë¶€ì„í•˜ì—¬'
                ],
                'weight': 0.1  # ê°€ì¤‘ì¹˜ ëŒ€í­ ë‚®ì¶¤ (0.3 -> 0.1): í‰ê°€ë¶ˆê°€ íŒì •ì„ ìµœì†Œí™”
            },
            # ê¸ì •ì  ê°ì • (ê¸°ì¨, ê°ì‚¬, ì‹ ë¢°, ê¸°ëŒ€, ì•ˆë„) - ê°€ì¤‘ì¹˜ +1
            1: {  # ê¸°ì¨
                'keywords': [
                    # ê¸°ë³¸ ê¸ì • í‘œí˜„
                    'í–‰ë³µ', 'ì¦ê±°ì›€', 'ê¸°ì¨', 'ì‹ ë‚¨', 'ì„¤ë ˜', 'ì›ƒìŒ', 'ì›ƒì—ˆë‹¤', 'ì›ƒê³ ', 'ì¦ê²', 'ì¬ë¯¸ìˆ', 'ì¬ë°Œ', 
                    'ì¢‹ì•˜', 'ì¢‹ë‹¤', 'ì¢‹ì•„', 'ë§Œì¡±', 'ê¸°ì˜', 'ì‹ ë‚˜', 'ì¦ê±°', 'í–‰ë³µí•˜', 'í–‰ë³µí•œ',
                    'ê¸°ë¶„ ì¢‹', 'ê¸°ë¶„ ì¢‹ì•˜', 'ê¸°ë¶„ ì¢‹ë‹¤', 'ê¸°ë¶„ ì¢‹ì•„', 'ê¸°ë¶„ì´ ì¢‹', 'ê¸°ë¶„ì´ ì¢‹ì•˜', 'ê¸°ë¶„ì´ ì¢‹ë‹¤',
                    'ë§›ìˆ', 'ë§›ìˆì–´', 'ë§›ìˆì—ˆ', 'ë§›ìˆë‹¤', 'ë§›ìˆë„¤', 'ë§›ìˆê³ ',
                    # ë¹„ì†ì–´/ì‹ ì¡°ì–´ - ê¸ì • ê°•ì¡° í‘œí˜„
                    'ê°œì¢‹', 'ê°œì©', 'ê°œì¬ë°Œ', 'ê°œì‹ ë‚˜', 'ê°œë§Œì¡±', 'ê°œí–‰ë³µ', 'ê°œì¦ê±°', 'ê°œê¸°ì¨', 'ê°œì›ƒê¹€', 'ê°œì›ƒê²¨',
                    'ì¡´ë‚˜ì¢‹', 'ì¡´ë‚˜ì¢‹ì•„', 'ì¡´ë‚˜ì¢‹ë‹¤', 'ì¡´ë§›', 'ì¡´ë§›íƒ±', 'ì¡´ì¬ë°Œ', 'ì¡´ì‹ ë‚˜', 'ì¡´ë§Œì¡±', 'ì¡´í–‰ë³µ',
                    'ì™„ì „ì¢‹', 'ì™„ì „ì¬ë°Œ', 'ì™„ì „í–‰ë³µ', 'ì™„ì „ë§Œì¡±', 'ì™„ì „ê¸°ì¨', 'ì™„ì „ì¦ê±°',
                    'ì§„ì§œì¢‹', 'ì§„ì§œì¬ë°Œ', 'ì§„ì§œí–‰ë³µ', 'ì§„ì§œë§Œì¡±', 'ì§„ì§œê¸°ì¨',
                    'ë„ˆë¬´ì¢‹', 'ë„ˆë¬´ì¬ë°Œ', 'ë„ˆë¬´í–‰ë³µ', 'ë„ˆë¬´ë§Œì¡±', 'ë„ˆë¬´ê¸°ì¨',
                    'ëŒ€ë°•', 'ëŒ€ë°•ë‚˜', 'ëŒ€ë°•ì´ì•¼', 'ëŒ€ë°•ì´ë‹¤',
                    'ìµœê³ ', 'ìµœê³ ë‹¤', 'ìµœê³ ì•¼', 'ìµœê³ ì„',
                    'ì§±', 'ì§±ì´ì•¼', 'ì§±ì´ë‹¤', 'ì§±ì„',
                    'í—', 'í—ëŒ€ë°•', 'í—ê°œì¢‹', 'í—ì¬ë°Œ'
                ],
                'weight': 1.5  # ë¹„ì†ì–´/ì‹ ì¡°ì–´ í¬í•¨ìœ¼ë¡œ ê°€ì¤‘ì¹˜ ì•½ê°„ ì¦ê°€
            },
            13: {  # ê°ì‚¬
                'keywords': ['ê°ì‚¬', 'ê³ ë§™', 'ê³ ë§ˆì›Œ', 'ê°ì‚¬í•˜', 'ê°ì‚¬í•œ', 'ê³ ë§ˆ', 'ê³ ë§™ë‹¤', 'ê°ì‚¬í•˜ë‹¤', 'ê³ ë§ˆì›Œìš”', 'ê³ ë§™ìŠµë‹ˆë‹¤'],
                'weight': 1.0
            },
            7: {  # ì‹ ë¢°
                'keywords': ['ë¯¿ìŒ', 'ë¯¿', 'ì‹ ë¢°', 'ë¯¿ì„', 'ë¯¿ê³ ', 'ë¯¿ëŠ”ë‹¤', 'ì‹ ë¢°í•˜', 'ì‹ ë¢°í• '],
                'weight': 1.0
            },
            8: {  # ê¸°ëŒ€
                'keywords': ['ê¸°ëŒ€', 'ê¸°ëŒ€ë˜', 'ê¸°ëŒ€í•œ', 'ê¸°ëŒ€í•˜', 'ê¸°ëŒ€ëœë‹¤', 'ê¸°ëŒ€ë¼', 'ê¸°ëŒ€í•´', 'ê¸°ëŒ€í• '],
                'weight': 1.0
            },
            10: {  # ì•ˆë„
                'keywords': ['ì•ˆì‹¬', 'í¸ì•ˆ', 'ì•ˆë„', 'ì•ˆë„ê°', 'ì•ˆì‹¬ë˜', 'í¸ì•ˆí•˜', 'í¸ì•ˆí•œ', 'ì•ˆì‹¬í•˜', 'ì•ˆë„í•˜', 'ì•ˆì‹¬ëœë‹¤', 'í¸ì•ˆí•˜ë‹¤'],
                'weight': 1.0
            },
            # ë¶€ì •ì  ê°ì • (ìŠ¬í””, ë¶„ë…¸, ë‘ë ¤ì›€, í˜ì˜¤, ë¶ˆì•ˆ, í›„íšŒ, ì™¸ë¡œì›€) - ê°€ì¤‘ì¹˜ +2
            2: {  # ìŠ¬í””
                'keywords': [
                    # ê¸°ë³¸ ìŠ¬í”” í‘œí˜„
                    'ìŠ¬í”„', 'ìŠ¬í””', 'ëˆˆë¬¼', 'ìš¸ì—ˆ', 'ìš¸ê³ ', 'ìŠ¬í¼', 'ìŠ¬í', 'ìŠ¬í”„ë‹¤', 'ìŠ¬í¼ì„œ', 'ëˆˆë¬¼ì´', 'ëˆˆë¬¼ì„', 'ìš°ìš¸', 'ìš°ìš¸í•˜', 'ìš°ìš¸í•œ', 'ìŠ¬í”„ë„¤', 'ìŠ¬í”„ê³ ',
                    'ì•„ì‰¬', 'ì•„ì‰¬ì›Œ', 'ì•„ì‰¬ì› ', 'ì•„ì‰¬ì› ë‹¤', 'ì•„ì‰½', 'ì•„ì‰½ë‹¤', 'ì•„ì‰¬ì›Œì„œ', 'ì•„ì‰¬ì› ì–´',
                    # ë¹„ì†ì–´/ì‹ ì¡°ì–´ - ìŠ¬í”” ê°•ì¡° í‘œí˜„
                    'ê°œìŠ¬í”„', 'ê°œìš°ìš¸', 'ê°œëˆˆë¬¼', 'ê°œìŠ¬í¼',
                    'ì¡´ë‚˜ìŠ¬í”„', 'ì¡´ë‚˜ìš°ìš¸', 'ì¡´ë‚˜ëˆˆë¬¼',
                    'ì™„ì „ìŠ¬í”„', 'ì™„ì „ìš°ìš¸', 'ì™„ì „ëˆˆë¬¼',
                    'ì§„ì§œìŠ¬í”„', 'ì§„ì§œìš°ìš¸', 'ì§„ì§œëˆˆë¬¼'
                ],
                'weight': 2.3  # ë¹„ì†ì–´/ì‹ ì¡°ì–´ í¬í•¨ìœ¼ë¡œ ê°€ì¤‘ì¹˜ ì¦ê°€ (2.5 -> 2.3: ë¶€ì • ê°ì • ê³¼ëŒ€í‰ê°€ ì™„í™”)
            },
            3: {  # ë¶„ë…¸
                'keywords': [
                    # ê¸°ë³¸ ë¶„ë…¸ í‘œí˜„
                    'í™”ë‚˜', 'í™”ë‚¬', 'ì§œì¦', 'ë¶„ë…¸', 'í™”ê°€', 'í™”ë‚¬ë‹¤', 'ì§œì¦ë‚˜', 'ì§œì¦ë‚¬', 'í™”ë‚˜ì„œ', 'ë¶„ë…¸í•˜', 'ë¶„ë…¸í•œ', 'í™”ë‚¬ì–´', 'ì§œì¦ë‚˜ë„¤', 'í™”ë‚˜ë„¤',
                    # ë¹„ì†ì–´/ì‹ ì¡°ì–´ - ë¶„ë…¸ ê°•ì¡° í‘œí˜„
                    'ê°œì§œì¦', 'ê°œí™”ë‚˜', 'ê°œë¶„ë…¸', 'ê°œë¹¡', 'ê°œë¹¡ì³', 'ê°œë¹¡ì³¤', 'ê°œë¹¡ì¹¨',
                    'ì¡´ë‚˜ì§œì¦', 'ì¡´ë‚˜í™”ë‚˜', 'ì¡´ë‚˜ë¶„ë…¸', 'ì¡´ë‚˜ë¹¡', 'ì¡´ë‚˜ë¹¡ì³',
                    'ì™„ì „ì§œì¦', 'ì™„ì „í™”ë‚˜', 'ì™„ì „ë¶„ë…¸', 'ì™„ì „ë¹¡',
                    'ì§„ì§œì§œì¦', 'ì§„ì§œí™”ë‚˜', 'ì§„ì§œë¶„ë…¸', 'ì§„ì§œë¹¡',
                    'ë„ˆë¬´ì§œì¦', 'ë„ˆë¬´í™”ë‚˜', 'ë„ˆë¬´ë¶„ë…¸',
                    'í•µì§œì¦', 'í•µë¹¡', 'í•µë¹¡ì¹¨'
                ],
                'weight': 2.3  # ë¹„ì†ì–´/ì‹ ì¡°ì–´ í¬í•¨ìœ¼ë¡œ ê°€ì¤‘ì¹˜ ì¦ê°€ (2.5 -> 2.3: ë¶€ì • ê°ì • ê³¼ëŒ€í‰ê°€ ì™„í™”)
            },
            4: {  # ë‘ë ¤ì›€
                'keywords': [
                    # ê¸°ë³¸ ë‘ë ¤ì›€ í‘œí˜„
                    'ë¬´ì„­', 'ë‘ë µ', 'ë‘ë ¤ì›€', 'ë¬´ì„œì›Œ', 'ë¬´ì„œì› ', 'ë‘ë ¤ì›Œ', 'ë‘ë ¤ì› ', 'ë¬´ì„œ', 'ë‘ë ¤', 'ë¬´ì„­ë‹¤', 'ë‘ë µë‹¤', 'ë¬´ì„œì› ë‹¤', 'ë‘ë ¤ì› ë‹¤', 'ë¬´ì„œì›Œì„œ', 'ë‘ë ¤ì›Œì„œ',
                    # ë¹„ì†ì–´/ì‹ ì¡°ì–´ - ë‘ë ¤ì›€ ê°•ì¡° í‘œí˜„
                    'ê°œë¬´ì„œ', 'ê°œë‘ë ¤', 'ê°œë¬´ì„­', 'ê°œë¬´ì„œì›Œ',
                    'ì¡´ë‚˜ë¬´ì„œ', 'ì¡´ë‚˜ë‘ë ¤', 'ì¡´ë‚˜ë¬´ì„­',
                    'ì™„ì „ë¬´ì„œ', 'ì™„ì „ë‘ë ¤', 'ì™„ì „ë¬´ì„­',
                    'ì§„ì§œë¬´ì„œ', 'ì§„ì§œë‘ë ¤', 'ì§„ì§œë¬´ì„­',
                    'ê²ë‚˜ë¬´ì„œ', 'ê²ë‚˜ë‘ë ¤', 'ê²ë‚˜ë¬´ì„­'
                ],
                'weight': 2.3  # ë¹„ì†ì–´/ì‹ ì¡°ì–´ í¬í•¨ìœ¼ë¡œ ê°€ì¤‘ì¹˜ ì¦ê°€ (2.5 -> 2.3: ë¶€ì • ê°ì • ê³¼ëŒ€í‰ê°€ ì™„í™”)
            },
            5: {  # í˜ì˜¤
                'keywords': [
                    # ê¸°ë³¸ í˜ì˜¤ í‘œí˜„
                    'ì‹«', 'í˜ì˜¤', 'ì‹«ì–´', 'ì‹«ë‹¤', 'ì‹«ì—ˆ', 'ì‹«ì€', 'í˜ì˜¤í•˜', 'í˜ì˜¤ìŠ¤ëŸ¬', 'ì‹«ì–´ì„œ', 'ì‹«ì–´ìš”', 'ì‹«ì–´í•´', 'í˜ì˜¤ìŠ¤ëŸ½', 'í˜ì˜¤ìŠ¤ëŸ¬ì›Œ',
                    # ë¹„ì†ì–´/ì‹ ì¡°ì–´ - í˜ì˜¤ ê°•ì¡° í‘œí˜„
                    'ê°œì‹«', 'ê°œì—­ê²¹', 'ê°œë”ëŸ¬ì›Œ', 'ê°œë”ëŸ¬ì›€', 'ê°œì§•ê·¸ëŸ¬ì›Œ', 'ê°œì§•ê·¸ëŸ½',
                    'ì¡´ë‚˜ì‹«', 'ì¡´ë‚˜ì—­ê²¹', 'ì¡´ë‚˜ë”ëŸ¬ì›Œ', 'ì¡´ë‚˜ì§•ê·¸ëŸ¬ì›Œ', 'ì¡´ë‚˜ì§•ê·¸ëŸ½',
                    'ì”¹ë…¸ë§›', 'ì”¹ê·¹í˜', 'ì”¹ì—­ê²¹', 'ì”¹ë”ëŸ¬ì›Œ', 'ì”¹ì§•ê·¸ëŸ¬ì›Œ',
                    'ì™„ì „ì‹«', 'ì™„ì „ì—­ê²¹', 'ì™„ì „ë”ëŸ¬ì›Œ', 'ì™„ì „ì§•ê·¸ëŸ¬ì›Œ',
                    'ì§„ì§œì‹«', 'ì§„ì§œì—­ê²¹', 'ì§„ì§œë”ëŸ¬ì›Œ', 'ì§„ì§œì§•ê·¸ëŸ¬ì›Œ',
                    'í•µë¶ˆì¾Œ', 'í•µì—­ê²¹', 'í•µë”ëŸ¬ì›Œ', 'í•µì§•ê·¸ëŸ¬ì›Œ',
                    'ê·¹í˜', 'í† ë‚˜ì™€', 'ìŒ‰', 'ìŒ‰ì‹«'
                ],
                'weight': 2.3  # ë¹„ì†ì–´/ì‹ ì¡°ì–´ í¬í•¨ìœ¼ë¡œ ê°€ì¤‘ì¹˜ ì¦ê°€ (2.5 -> 2.3: ë¶€ì • ê°ì • ê³¼ëŒ€í‰ê°€ ì™„í™”)
            },
            9: {  # ë¶ˆì•ˆ
                'keywords': [
                    # ê¸°ë³¸ ë¶ˆì•ˆ í‘œí˜„
                    'ë¶ˆì•ˆ', 'ê±±ì •', 'ë¶ˆì•ˆí•˜', 'ë¶ˆì•ˆí•œ', 'ê±±ì •ë˜', 'ê±±ì •í•˜', 'ê±±ì •ì´', 'ë¶ˆì•ˆí•´', 'ë¶ˆì•ˆí•˜ë‹¤', 'ê±±ì •ëœë‹¤', 'ê±±ì •ë¼', 'ë¶ˆì•ˆê°', 'ê±±ì •ìŠ¤ëŸ¬',
                    # ë¹„ì†ì–´/ì‹ ì¡°ì–´ - ë¶ˆì•ˆ ê°•ì¡° í‘œí˜„
                    'ê°œë¶ˆì•ˆ', 'ê°œê±±ì •', 'ê°œê±±ì •ë˜', 'ê°œê±±ì •ë¼',
                    'ì¡´ë‚˜ë¶ˆì•ˆ', 'ì¡´ë‚˜ê±±ì •', 'ì¡´ë‚˜ê±±ì •ë˜',
                    'ì™„ì „ë¶ˆì•ˆ', 'ì™„ì „ê±±ì •', 'ì™„ì „ê±±ì •ë˜',
                    'ì§„ì§œë¶ˆì•ˆ', 'ì§„ì§œê±±ì •', 'ì§„ì§œê±±ì •ë˜'
                ],
                'weight': 2.3  # ë¹„ì†ì–´/ì‹ ì¡°ì–´ í¬í•¨ìœ¼ë¡œ ê°€ì¤‘ì¹˜ ì¦ê°€ (2.5 -> 2.3: ë¶€ì • ê°ì • ê³¼ëŒ€í‰ê°€ ì™„í™”)
            },
            11: {  # í›„íšŒ
                'keywords': ['í›„íšŒ', 'í›„íšŒí•˜', 'í›„íšŒí•œ', 'í›„íšŒë˜', 'í›„íšŒë¼', 'í›„íšŒí•´', 'í›„íšŒí•œë‹¤', 'í›„íšŒí•˜ê³ ', 'í›„íšŒí–ˆ', 'í›„íšŒí• '],
                'weight': 1.8  # 2.0 -> 1.8: ë¶€ì • ê°ì • ê³¼ëŒ€í‰ê°€ ì™„í™”
            },
            14: {  # ì™¸ë¡œì›€
                'keywords': ['ì™¸ë¡­', 'ì™¸ë¡œì›€', 'ì™¸ë¡œì›Œ', 'ì™¸ë¡œì› ', 'ì™¸ë¡­ë‹¤', 'ì™¸ë¡œì›Œì„œ', 'ì™¸ë¡œì› ë‹¤', 'ì™¸ë¡­ë„¤', 'ì™¸ë¡­ê³ ', 'ì™¸ë¡œì›Œìš”'],
                'weight': 1.8  # 2.0 -> 1.8: ë¶€ì • ê°ì • ê³¼ëŒ€í‰ê°€ ì™„í™”
            },
            # ì¤‘ë¦½ì  ê°ì • (ê·¸ë¦¬ì›€, ë†€ëŒ) - ìµœì†Œ ê°€ì¤‘ì¹˜
            12: {  # ê·¸ë¦¬ì›€
                'keywords': ['ê·¸ë¦½', 'ê·¸ë¦¬ì›€', 'ê·¸ë¦¬ì›Œ', 'ê·¸ë¦¬ì› ', 'ê·¸ë¦¬ë‹¤', 'ê·¸ë¦¬ì›Œì„œ', 'ê·¸ë¦¬ì› ë‹¤', 'ë³´ê³ ì‹¶', 'ë³´ê³ ì‹¶ì–´', 'ë³´ê³ ì‹¶ë‹¤', 'ë³´ê³ ì‹¶ì—ˆ'],
                'weight': 0.5
            },
            6: {  # ë†€ëŒ
                'keywords': ['ë†€ë', 'ë†€ëŒ', 'ë†€ë¼', 'ë†€ë', 'ì˜ì™¸', 'ë†€ëë‹¤', 'ë†€ë¼ì›Œ', 'ë†€ë¼ì› ', 'ì˜ì™¸ë‹¤', 'ì˜ì™¸ë„¤', 'ë†€ë¼ì„œ', 'ë†€ëì–´'],
                'weight': 0.5
            }
        }
        
        # ê° ê°ì •ë³„ë¡œ í‚¤ì›Œë“œ ë§¤ì¹­ ë° ê°€ì¤‘ì¹˜ ê³„ì‚°
        weight_scores = np.zeros(len(probabilities))
        
        for emotion_id, config in keyword_weights.items():
            if emotion_id >= len(probabilities):
                continue
                
            keywords = config['keywords']
            weight = config['weight']
            
            # í‚¤ì›Œë“œ ë§¤ì¹­ ê°œìˆ˜ ê³„ì‚°
            match_count = sum(1 for keyword in keywords if keyword in text_lower)
            
            # í‚¤ì›Œë“œ ë§¤ì¹­ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ì ìš© (Word2Vec ì œê±°ë¨)
            if match_count > 0:
                # í‚¤ì›Œë“œê°€ ë°œê²¬ë˜ë©´ ê°€ì¤‘ì¹˜ ì ìš© (ë§¤ì¹­ ê°œìˆ˜ì— ë¹„ë¡€)
                weight_scores[emotion_id] = match_count * weight
                ic(f"ê°ì • {emotion_labels.get(emotion_id, emotion_id)}: {match_count}ê°œ í‚¤ì›Œë“œ ë§¤ì¹­, ê°€ì¤‘ì¹˜ {weight_scores[emotion_id]:.3f}")
        
        # ê°€ì¤‘ì¹˜ë¥¼ í™•ë¥ ì— ì ìš© (ì†Œí”„íŠ¸ë§¥ìŠ¤ ë°©ì‹)
        if weight_scores.sum() > 0:
            # ê°€ì¤‘ì¹˜ë¥¼ ì •ê·œí™”í•˜ì—¬ í™•ë¥ ì— ë”í•¨
            normalized_weights = weight_scores / (weight_scores.sum() + 1e-10) * 0.25  # ìµœëŒ€ 25% ë³´ì • (15% -> 25%ë¡œ ì¦ê°€)
            adjusted_probs = probabilities + normalized_weights
            
            # í‰ê°€ë¶ˆê°€ í™•ë¥  ì¶”ê°€ ê°ì†Œ: ë‹¤ë¥¸ ê°ì • í‚¤ì›Œë“œê°€ ë°œê²¬ë˜ë©´ í‰ê°€ë¶ˆê°€ í™•ë¥ ì„ ë” ë‚®ì¶¤
            if len(probabilities) > 0:
                # í‰ê°€ë¶ˆê°€(0ë²ˆ)ë¥¼ ì œì™¸í•œ ë‹¤ë¥¸ ê°ì •ì˜ ê°€ì¤‘ì¹˜ í•© ê³„ì‚°
                other_emotions_weight = weight_scores[1:].sum() if len(weight_scores) > 1 else 0
                
                # ë‹¤ë¥¸ ê°ì • í‚¤ì›Œë“œê°€ ë°œê²¬ë˜ì—ˆê³  í‰ê°€ë¶ˆê°€ í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ í‰ê°€ë¶ˆê°€ í™•ë¥  ê°ì†Œ
                if other_emotions_weight > 0 and weight_scores[0] == 0:
                    # í‰ê°€ë¶ˆê°€ í™•ë¥ ì„ 10% ê°ì†Œ
                    adjusted_probs[0] = adjusted_probs[0] * 0.9
                    ic(f"ë‹¤ë¥¸ ê°ì • í‚¤ì›Œë“œ ë°œê²¬ ({other_emotions_weight:.2f}), í‰ê°€ë¶ˆê°€ í™•ë¥  10% ê°ì†Œ")
                elif other_emotions_weight > weight_scores[0] * 2:
                    # ë‹¤ë¥¸ ê°ì • í‚¤ì›Œë“œê°€ í‰ê°€ë¶ˆê°€ í‚¤ì›Œë“œë³´ë‹¤ 2ë°° ì´ìƒ ë§ìœ¼ë©´ í‰ê°€ë¶ˆê°€ í™•ë¥  10% ê°ì†Œ
                    adjusted_probs[0] = adjusted_probs[0] * 0.9
                    ic(f"ë‹¤ë¥¸ ê°ì • í‚¤ì›Œë“œê°€ ìš°ì„¸ ({other_emotions_weight:.2f} vs {weight_scores[0]:.2f}), í‰ê°€ë¶ˆê°€ í™•ë¥  10% ê°ì†Œ")
            
            # í™•ë¥ ì´ 1ì„ ë„˜ì§€ ì•Šë„ë¡ ì •ê·œí™”
            adjusted_probs = adjusted_probs / (adjusted_probs.sum() + 1e-10)
            
            return adjusted_probs
        
        return probabilities
    
    def _apply_emotion_weights(self, probabilities: np.ndarray, emotion_labels: Dict[int, str]) -> np.ndarray:
        """
        ê°ì •ë³„ ê°€ì¤‘ì¹˜ ì¡°ì • (DL ëª¨ë¸ìš© - ë¯¸ì„¸ ì¡°ì •)
        
        DL ëª¨ë¸ì€ BERT/ELECTRA ê°™ì€ ì‚¬ì „ í•™ìŠµ ëª¨ë¸ë¡œ ë¬¸ë§¥ì„ ì˜ ì´í•´í•˜ë¯€ë¡œ,
        ML ëª¨ë¸ë³´ë‹¤ í›¨ì”¬ ì‘ì€ ê°€ì¤‘ì¹˜ ì¡°ì •ë§Œ ì ìš©í•©ë‹ˆë‹¤.
        
        Args:
            probabilities: ê°ì •ë³„ í™•ë¥  ë°°ì—´ (15ê°œ í´ë˜ìŠ¤)
            emotion_labels: ê°ì • ë¼ë²¨ ë”•ì…”ë„ˆë¦¬
        
        Returns:
            ê°€ì¤‘ì¹˜ ì¡°ì •ëœ í™•ë¥  ë°°ì—´
        """
        # DL ëª¨ë¸ì€ ì´ë¯¸ ë¬¸ë§¥ì„ ì˜ ì´í•´í•˜ë¯€ë¡œ í° ì¡°ì • ë¶ˆí•„ìš”
        # í•„ìš”ì‹œ ë¯¸ì„¸ ì¡°ì •ë§Œ ì ìš© (ì˜ˆ: 5-10% ìˆ˜ì¤€)
        
        # í™•ë¥  ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (ê°€ì¤‘ì¹˜ ì¡°ì • í¸ì˜ë¥¼ ìœ„í•´)
        prob_dict = {}
        for idx, label in emotion_labels.items():
            if idx < len(probabilities):
                prob_dict[label] = float(probabilities[idx])
        
        # DL ëª¨ë¸ìš© ë¯¸ì„¸ ê°€ì¤‘ì¹˜ ì¡°ì • (MLì˜ 1.2/0.8 ëŒ€ì‹  1.05/0.95 ìˆ˜ì¤€)
        # ë¶ˆì•ˆ: ì•½ê°„ ì¦ê°€ (5% ì¦ê°€) - MLì˜ 20% ì¦ê°€ ëŒ€ë¹„ ë§¤ìš° ì‘ìŒ
        if "ë¶ˆì•ˆ" in prob_dict and prob_dict["ë¶ˆì•ˆ"] > 0.1:  # ë¶ˆì•ˆ í™•ë¥ ì´ ì¼ì • ìˆ˜ì¤€ ì´ìƒì¼ ë•Œë§Œ
            prob_dict["ë¶ˆì•ˆ"] *= 1.05
            ic(f"DL ë¶ˆì•ˆ í™•ë¥  ë¯¸ì„¸ ì¡°ì •: {prob_dict['ë¶ˆì•ˆ']:.4f}")
        
        # ê¸°ëŒ€: ì•½ê°„ ê°ì†Œ (5% ê°ì†Œ) - MLì˜ 20% ê°ì†Œ ëŒ€ë¹„ ë§¤ìš° ì‘ìŒ
        if "ê¸°ëŒ€" in prob_dict and prob_dict["ê¸°ëŒ€"] > 0.1:  # ê¸°ëŒ€ í™•ë¥ ì´ ì¼ì • ìˆ˜ì¤€ ì´ìƒì¼ ë•Œë§Œ
            prob_dict["ê¸°ëŒ€"] *= 0.95
            ic(f"DL ê¸°ëŒ€ í™•ë¥  ë¯¸ì„¸ ì¡°ì •: {prob_dict['ê¸°ëŒ€']:.4f}")
        
        # ë”•ì…”ë„ˆë¦¬ë¥¼ ë‹¤ì‹œ ë°°ì—´ë¡œ ë³€í™˜
        adjusted_probs = np.array([prob_dict.get(emotion_labels.get(i, ''), 0.0) for i in range(len(probabilities))])
        
        # ì •ê·œí™” ì „ í™•ì¸ (ë””ë²„ê¹…)
        before_norm_max = float(np.max(adjusted_probs))
        before_norm_sum = float(adjusted_probs.sum())
        
        # ì •ê·œí™” (í™•ë¥  í•©ì´ 1ì´ ë˜ë„ë¡)
        adjusted_probs = adjusted_probs / (adjusted_probs.sum() + 1e-10)
        
        # ì •ê·œí™” í›„ í™•ì¸ (ë””ë²„ê¹…)
        after_norm_max = float(np.max(adjusted_probs))
        after_norm_sum = float(adjusted_probs.sum())
        ic(f"DL ê°€ì¤‘ì¹˜ ì¡°ì •: ì •ê·œí™” ì „ ìµœëŒ€={before_norm_max:.4f}, í•©={before_norm_sum:.4f} -> ì •ê·œí™” í›„ ìµœëŒ€={after_norm_max:.4f}, í•©={after_norm_sum:.4f}")
        
        return adjusted_probs
    
    def _try_load_model(self):
        """ëª¨ë¸ íŒŒì¼ì´ ìˆìœ¼ë©´ ìë™ ë¡œë“œ (DL ì „ìš©)"""
        try:
            # DL ëª¨ë¸ ìë™ ë¡œë“œ
            if self.dl_model_file.exists():
                ic("DL ëª¨ë¸ íŒŒì¼ ë°œê²¬, ìë™ ë¡œë“œ ì‹œë„...")
                return self._load_model_dl()
            
            return False
        except Exception as e:
            ic(f"ëª¨ë¸ ìë™ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def save_model(self):
        """ëª¨ë¸ì„ íŒŒì¼ë¡œ ì €ì¥ (DL ì „ìš©)"""
        return self._save_model_dl()
    
    def _save_model_dl(self):
        """DL ëª¨ë¸ ì €ì¥"""
        try:
            if not DL_AVAILABLE:
                raise ImportError("ë”¥ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            if self.dl_model_obj is None or self.dl_model_obj.model is None:
                raise ValueError("DL ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. learning()ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
            
            # ëª¨ë¸ ë””ë ‰í† ë¦¬ ìƒì„±
            self.model_dir.mkdir(parents=True, exist_ok=True)
            
            # ëª¨ë¸ ì €ì¥ (PyTorch)
            # ë¡œì»¬ GPUì—ì„œ í•™ìŠµí•œ ëª¨ë¸ì„ ì»¨í…Œì´ë„ˆì—ì„œë„ ì‚¬ìš© ê°€ëŠ¥í•˜ë„ë¡ CPUë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
            import torch
            model_state_dict = self.dl_model_obj.model.state_dict()
            
            # GPUì—ì„œ í•™ìŠµí•œ ëª¨ë¸ì„ CPUë¡œ ë³€í™˜ (ì»¨í…Œì´ë„ˆ í˜¸í™˜ì„±)
            cpu_state_dict = {}
            for key, value in model_state_dict.items():
                cpu_state_dict[key] = value.cpu()
            
            # ëª¨ë¸ êµ¬ì¡° ì •ë³´ ì¶”ì¶œ (hidden_size í™•ì¸)
            hidden_size = None
            if hasattr(self.dl_model_obj.model, 'classifier'):
                classifier = self.dl_model_obj.model.classifier
                # Sequentialì¸ ê²½ìš° (2-layer): classifier[0]ì´ Linear
                if isinstance(classifier, torch.nn.Sequential) and len(classifier) > 0:
                    if isinstance(classifier[0], torch.nn.Linear):
                        hidden_size = classifier[0].out_features
                # Linearì¸ ê²½ìš° (1-layer): hidden_sizeëŠ” None
                elif isinstance(classifier, torch.nn.Linear):
                    hidden_size = None
            
            torch.save({
                'model_state_dict': cpu_state_dict,  # CPUë¡œ ë³€í™˜ëœ ìƒíƒœ ì €ì¥
                'model_name': self.dl_model_obj.model_name,
                'num_labels': self.dl_model_obj.num_labels,
                'max_length': self.dl_model_obj.max_length,
                'hidden_size': hidden_size  # ëª¨ë¸ êµ¬ì¡° ì •ë³´ ì €ì¥
            }, self.dl_model_file)
            ic(f"DL ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {self.dl_model_file} (CPU í˜¸í™˜ í˜•ì‹ìœ¼ë¡œ ì €ì¥, hidden_size={hidden_size})")
            
            # ë©”íƒ€ë°ì´í„° ì €ì¥
            csv_mtime = self.csv_file_path.stat().st_mtime
            metadata = {
                'model_type': 'dl',
                'model_name': self.dl_model_obj.model_name,
                'num_labels': self.dl_model_obj.num_labels,  # ê°ì • í´ë˜ìŠ¤ ìˆ˜ ì €ì¥
                'max_length': self.dl_model_obj.max_length,
                'hidden_size': hidden_size,  # ëª¨ë¸ êµ¬ì¡° ì •ë³´ ì €ì¥
                'csv_mtime': csv_mtime,
                'csv_path': str(self.csv_file_path),
                'trained_at': datetime.now().isoformat(),
                'data_count': len(self.df) if self.df is not None else 0
            }
            with open(self.dl_metadata_file, 'wb') as f:
                pickle.dump(metadata, f)
            ic(f"DL ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ: {self.dl_metadata_file}")
            
        except Exception as e:
            ic(f"DL ëª¨ë¸ ì €ì¥ ì˜¤ë¥˜: {e}")
            raise
    
    def load_model(self):
        """ëª¨ë¸ ë¡œë“œ (DL ì „ìš©)"""
        return self._load_model_dl()
    
    def _load_model_dl(self):
        """DL ëª¨ë¸ ë¡œë“œ"""
        try:
            if not DL_AVAILABLE:
                ic("ë”¥ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return False
            
            # torch import (í•¨ìˆ˜ ì‹œì‘ ë¶€ë¶„ì—ì„œ)
            import torch
            
            if not self.dl_model_file.exists():
                ic(f"DL ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {self.dl_model_file}")
                return False
            
            # ë©”íƒ€ë°ì´í„° ë¡œë“œ
            with open(self.dl_metadata_file, 'rb') as f:
                metadata = pickle.load(f)
            
            # ëª¨ë¸ ì´ˆê¸°í™”
            if self.dl_model_obj is None:
                # ë©”íƒ€ë°ì´í„°ì—ì„œ num_labels ê°€ì ¸ì˜¤ê¸° (ì—†ìœ¼ë©´ ë™ì  ê³„ì‚°)
                num_labels = metadata.get('num_labels', None)
                if num_labels is None and self.df is not None and 'emotion' in self.df.columns:
                    unique_emotions = self.df['emotion'].unique()
                    num_labels = len(unique_emotions)
                elif num_labels is None:
                    num_labels = 15  # ê¸°ë³¸ê°’
                
                self.dl_model_obj = DiaryEmotionDLModel(
                    model_name=metadata['model_name'],
                    num_labels=num_labels,
                    max_length=metadata.get('max_length', 512)
                )
            
            # ë©”íƒ€ë°ì´í„°ì—ì„œ hidden_size ê°€ì ¸ì˜¤ê¸° (ëª¨ë¸ êµ¬ì¡° ì¼ì¹˜)
            hidden_size = metadata.get('hidden_size', None)
            # checkpointì—ì„œë„ í™•ì¸ (ë©”íƒ€ë°ì´í„°ì— ì—†ì„ ê²½ìš°)
            if hidden_size is None:
                checkpoint = torch.load(self.dl_model_file, map_location='cpu')
                hidden_size = checkpoint.get('hidden_size', None)
            
            ic(f"ëª¨ë¸ ë¡œë“œ: hidden_size={hidden_size} (Noneì´ë©´ 1-layer, ê°’ì´ ìˆìœ¼ë©´ 2-layer)")
            self.dl_model_obj.create_model(dropout_rate=0.3, hidden_size=hidden_size)
            
            # ëª¨ë¸ ìƒíƒœ ë¡œë“œ
            checkpoint = torch.load(self.dl_model_file, map_location=self.dl_model_obj.device)
            self.dl_model_obj.model.load_state_dict(checkpoint['model_state_dict'])
            self.dl_model_obj.model.eval()
            
            # íŠ¸ë ˆì´ë„ˆ ìƒì„±
            self.dl_trainer = DiaryEmotionDLTrainer(
                model=self.dl_model_obj.model,
                tokenizer=self.dl_model_obj.tokenizer,
                device=self.dl_model_obj.device
            )
            
            ic("DL ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            return True
            
        except Exception as e:
            ic(f"DL ëª¨ë¸ ë¡œë“œ ì˜¤ë¥˜: {e}")
            return False
    
    def submit(self):
        """ì œì¶œ/ëª¨ë¸ ì €ì¥"""
        ic("ğŸ˜ğŸ˜ ì œì¶œ ì‹œì‘")
        self.save_model()
        ic("ğŸ˜ğŸ˜ ì œì¶œ ì™„ë£Œ")


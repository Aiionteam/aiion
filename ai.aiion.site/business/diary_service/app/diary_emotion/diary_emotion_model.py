"""
Diary Emotion Model
ì¼ê¸° ê°ì • ë¶„ë¥˜ ë¨¸ì‹ ëŸ¬ë‹/ë”¥ëŸ¬ë‹ ëª¨ë¸ í´ë˜ìŠ¤
"""

import pandas as pd
import numpy as np
from icecream import ic
from typing import Optional

# PyTorch ë° Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
try:
    import torch
    import torch.nn as nn
    from transformers import (
        AutoTokenizer,
        AutoModel,
        AutoConfig,
    )
    TORCH_AVAILABLE = True
    DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
except ImportError:
    TORCH_AVAILABLE = False
    DEVICE = None
    ic("ê²½ê³ : torch ë˜ëŠ” transformersê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


class DiaryEmotionModel:
    """ì¼ê¸° ê°ì • ë¶„ë¥˜ ML ëª¨ë¸ í´ë˜ìŠ¤ (ê¸°ì¡´)"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.model = None
        self.scaler = None
        self.vectorizer = None
        # Word2Vec ì œê±°ë¨ - BERTê°€ ë” ìš°ìˆ˜í•œ ë¬¸ë§¥ ì´í•´ë¥¼ ì œê³µ
        self.label_encoder = None
        ic("DiaryEmotionModel ì´ˆê¸°í™”")
    
    def __repr__(self) -> str:
        """ë¬¸ìì—´ í‘œí˜„"""
        return f"DiaryEmotionModel(model={self.model is not None})"


class BERTEmotionClassifier(nn.Module):
    """BERT ê¸°ë°˜ ê°ì • ë¶„ë¥˜ ë”¥ëŸ¬ë‹ ëª¨ë¸"""
    
    def __init__(
        self,
        model_name: str = "klue/bert-base",
        num_labels: int = 7,
        dropout_rate: float = 0.3,
        hidden_size: Optional[int] = None
    ):
        """
        ì´ˆê¸°í™”
        
        Args:
            model_name: HuggingFace ëª¨ë¸ ì´ë¦„ ë˜ëŠ” ë¡œì»¬ ëª¨ë¸ ê²½ë¡œ (ê¸°ë³¸: klue/bert-base)
                       ì˜ˆ: "klue/bert-base" ë˜ëŠ” "koelectro_v3_base" ë˜ëŠ” Path ê°ì²´
            num_labels: ê°ì • ë¼ë²¨ ìˆ˜ (0:í‰ê°€ë¶ˆê°€, 1:ê¸°ì¨, 2:ìŠ¬í””, 3:ë¶„ë…¸, 4:ë‘ë ¤ì›€, 5:í˜ì˜¤, 6:ë†€ëŒ, 7:ì‹ ë¢°, 8:ê¸°ëŒ€, 9:ë¶ˆì•ˆ, 10:ì•ˆë„, 11:í›„íšŒ, 12:ê·¸ë¦¬ì›€, 13:ê°ì‚¬, 14:ì™¸ë¡œì›€)
            dropout_rate: Dropout ë¹„ìœ¨
            hidden_size: ì¤‘ê°„ hidden layer í¬ê¸° (Noneì´ë©´ ì§ì ‘ ë¶„ë¥˜)
        """
        super().__init__()
        if not TORCH_AVAILABLE:
            raise ImportError("torchì™€ transformersê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ë¡œì»¬ ëª¨ë¸ ê²½ë¡œì¸ì§€ í™•ì¸
        from pathlib import Path
        model_path_str = str(model_name)
        
        # ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜ (ê³µí†µ ëª¨ë¸ ì €ì¥ì†Œ ìš°ì„ )
        if not Path(model_path_str).is_absolute():
            # 1. Docker í™˜ê²½: /app/koelectro_v3_base (ìš°ì„ )
            docker_path = Path("/app/koelectro_v3_base")
            if docker_path.exists() and docker_path.is_dir() and (docker_path / "config.json").exists():
                model_path_str = str(docker_path)
                ic(f"âœ… Docker ê³µí†µ ëª¨ë¸ ì €ì¥ì†Œ ì‚¬ìš©: {model_path_str}")
            # 2. ê³µí†µ ëª¨ë¸ ì €ì¥ì†Œ: ai.aiion.site/models/koelectra
            elif model_name == "koelectro_v3_base":
                # business/diary_service/appì´ ë£¨íŠ¸ì´ë¯€ë¡œ ìƒìœ„ë¡œ ì˜¬ë¼ê°€ì„œ ì°¾ê¸°
                current_dir = Path(__file__).parent  # diary_emotion
                app_dir = current_dir.parent  # app
                service_dir = app_dir.parent  # diary_service
                business_dir = service_dir.parent  # business
                ai_dir = business_dir.parent  # ai.aiion.site
                common_model_path = ai_dir / "models" / "koelectra"
                if common_model_path.exists() and common_model_path.is_dir() and (common_model_path / "config.json").exists():
                    model_path_str = str(common_model_path)
                    ic(f"âœ… ê³µí†µ ëª¨ë¸ ì €ì¥ì†Œ ì‚¬ìš©: {model_path_str}")
                else:
                    # 3. ê¸°ì¡´ ìœ„ì¹˜ (í•˜ìœ„ í˜¸í™˜ì„±)
                    potential_path = app_dir / model_path_str
                    if potential_path.exists() and potential_path.is_dir():
                        model_path_str = str(potential_path)
                    else:
                        potential_path = ai_dir / model_path_str
                        if potential_path.exists() and potential_path.is_dir():
                            model_path_str = str(potential_path)
        
        model_path = Path(model_path_str)
        is_local_model = model_path.exists() and model_path.is_dir() and (model_path / "config.json").exists()
        
        if is_local_model:
            # ë¡œì»¬ ëª¨ë¸ ë¡œë“œ
            ic(f"âœ… ë¡œì»¬ ëª¨ë¸ ë¡œë“œ: {model_path}")
            self.config = AutoConfig.from_pretrained(str(model_path))
            self.bert = AutoModel.from_pretrained(str(model_path))
        else:
            # HuggingFace ëª¨ë¸ ë¡œë“œ
            ic(f"ğŸŒ HuggingFace ëª¨ë¸ ë¡œë“œ: {model_name}")
            self.config = AutoConfig.from_pretrained(model_name)
            self.bert = AutoModel.from_pretrained(model_name)
        self.dropout = nn.Dropout(dropout_rate)
        
        # ë¶„ë¥˜ í—¤ë“œ
        if hidden_size:
            # 2-layer ë¶„ë¥˜ê¸°
            self.classifier = nn.Sequential(
                nn.Linear(self.config.hidden_size, hidden_size),
                nn.ReLU(),
                nn.Dropout(dropout_rate),
                nn.Linear(hidden_size, num_labels)
            )
        else:
            # 1-layer ë¶„ë¥˜ê¸°
            self.classifier = nn.Linear(self.config.hidden_size, num_labels)
        
        self.num_labels = num_labels
        self.model_name = model_name
        ic(f"BERTEmotionClassifier ì´ˆê¸°í™” ì™„ë£Œ: {model_name}, labels={num_labels}")
    
    def forward(
        self,
        input_ids: torch.Tensor,
        attention_mask: torch.Tensor,
        token_type_ids: Optional[torch.Tensor] = None
    ):
        """
        ìˆœì „íŒŒ
        
        Args:
            input_ids: í† í° ID
            attention_mask: Attention mask
            token_type_ids: Token type IDs (ì„ íƒ)
        
        Returns:
            logits: ê° í´ë˜ìŠ¤ì— ëŒ€í•œ ë¡œì§“ (batch_size, num_labels)
        """
        # BERT ì¸ì½”ë”©
        outputs = self.bert(
            input_ids=input_ids,
            attention_mask=attention_mask,
            token_type_ids=token_type_ids
        )
        
        # [CLS] í† í°ì˜ hidden state ì¶”ì¶œ
        pooled_output = outputs.last_hidden_state[:, 0, :]  # (batch_size, hidden_size)
        
        # Dropout ë° ë¶„ë¥˜
        pooled_output = self.dropout(pooled_output)
        logits = self.classifier(pooled_output)
        
        return logits
    
    def freeze_bert_layers(self, num_layers_to_freeze: int = 8):
        """
        BERT í•˜ìœ„ ë ˆì´ì–´ë¥¼ ë™ê²°í•˜ì—¬ í•™ìŠµ ì†ë„ í–¥ìƒ
        
        Args:
            num_layers_to_freeze: ë™ê²°í•  ë ˆì´ì–´ ìˆ˜ (ê¸°ë³¸: 8, BERT-baseëŠ” ì´ 12 layers)
        """
        # Embedding layer ë™ê²°
        for param in self.bert.embeddings.parameters():
            param.requires_grad = False
        
        # ì§€ì •ëœ ìˆ˜ë§Œí¼ encoder layer ë™ê²°
        for i in range(num_layers_to_freeze):
            if i < len(self.bert.encoder.layer):
                for param in self.bert.encoder.layer[i].parameters():
                    param.requires_grad = False
        
        ic(f"BERT í•˜ìœ„ {num_layers_to_freeze}ê°œ ë ˆì´ì–´ ë™ê²° ì™„ë£Œ")
    
    def unfreeze_all(self):
        """ëª¨ë“  ë ˆì´ì–´ ë™ê²° í•´ì œ"""
        for param in self.parameters():
            param.requires_grad = True
        ic("ëª¨ë“  ë ˆì´ì–´ ë™ê²° í•´ì œ ì™„ë£Œ")


class DiaryEmotionDLModel:
    """ì¼ê¸° ê°ì • ë¶„ë¥˜ DL ëª¨ë¸ ë˜í¼ í´ë˜ìŠ¤"""
    
    def __init__(
        self,
        model_name: str = "koelectro_v3_base",  # ë¡œì»¬ KoELECTRA v3 base ëª¨ë¸ (ê¸°ë³¸ê°’)
        num_labels: int = 7,
        max_length: int = 512,
        device: Optional[torch.device] = None
    ):
        """
        ì´ˆê¸°í™”
        
        Args:
            model_name: HuggingFace ëª¨ë¸ ì´ë¦„ ë˜ëŠ” ë¡œì»¬ ëª¨ë¸ ê²½ë¡œ (ê¸°ë³¸: koelectro_v3_base)
            num_labels: ê°ì • ë¼ë²¨ ìˆ˜
            max_length: ìµœëŒ€ í† í° ê¸¸ì´
            device: ë””ë°”ì´ìŠ¤ (Noneì´ë©´ ìë™ ê°ì§€)
        """
        if not TORCH_AVAILABLE:
            raise ImportError("torchì™€ transformersê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        self.model_name = model_name
        self.num_labels = num_labels
        self.max_length = max_length
        # deviceê°€ Noneì´ë©´ ëŸ°íƒ€ì„ì— ë‹¤ì‹œ í™•ì¸ (ëª¨ë“ˆ ë¡œë“œ ì‹œì ì˜ DEVICEëŠ” ë¬´ì‹œ)
        if device is None:
            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        else:
            self.device = device
        
        # í† í¬ë‚˜ì´ì € ë¡œë“œ (ë¡œì»¬ ëª¨ë¸ ê²½ë¡œ ì§€ì›)
        from pathlib import Path
        model_path_str = str(self.model_name)
        
        # ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜ (ê³µí†µ ëª¨ë¸ ì €ì¥ì†Œ ìš°ì„ )
        if not Path(model_path_str).is_absolute():
            # 1. Docker í™˜ê²½: /app/koelectro_v3_base (ìš°ì„ )
            docker_path = Path("/app/koelectro_v3_base")
            if docker_path.exists() and docker_path.is_dir() and (docker_path / "config.json").exists():
                model_path_str = str(docker_path)
                ic(f"âœ… Docker ê³µí†µ ëª¨ë¸ ì €ì¥ì†Œ ì‚¬ìš©: {model_path_str}")
            # 2. ê³µí†µ ëª¨ë¸ ì €ì¥ì†Œ: ai.aiion.site/models/koelectra
            elif model_name == "koelectro_v3_base":
                # business/diary_service/appì´ ë£¨íŠ¸ì´ë¯€ë¡œ ìƒìœ„ë¡œ ì˜¬ë¼ê°€ì„œ ì°¾ê¸°
                current_dir = Path(__file__).parent  # diary_emotion
                app_dir = current_dir.parent  # app
                service_dir = app_dir.parent  # diary_service
                business_dir = service_dir.parent  # business
                ai_dir = business_dir.parent  # ai.aiion.site
                common_model_path = ai_dir / "models" / "koelectra"
                ic(f"ëª¨ë¸ ê²½ë¡œ ê²€ìƒ‰ (ê³µí†µ ì €ì¥ì†Œ): {common_model_path} (ì¡´ì¬: {common_model_path.exists()})")
                if common_model_path.exists() and common_model_path.is_dir() and (common_model_path / "config.json").exists():
                    model_path_str = str(common_model_path)
                    ic(f"âœ… ê³µí†µ ëª¨ë¸ ì €ì¥ì†Œ ì‚¬ìš©: {model_path_str}")
                else:
                    # 3. ê¸°ì¡´ ìœ„ì¹˜ (í•˜ìœ„ í˜¸í™˜ì„±)
                    potential_path = app_dir / model_path_str
                    ic(f"ëª¨ë¸ ê²½ë¡œ ê²€ìƒ‰ 1: {potential_path} (ì¡´ì¬: {potential_path.exists()})")
                    if potential_path.exists() and potential_path.is_dir() and (potential_path / "config.json").exists():
                        model_path_str = str(potential_path)
                        ic(f"âœ… ëª¨ë¸ ê²½ë¡œ ë°œê²¬ (app): {model_path_str}")
                    else:
                        potential_path = ai_dir / model_path_str
                        ic(f"ëª¨ë¸ ê²½ë¡œ ê²€ìƒ‰ 2: {potential_path} (ì¡´ì¬: {potential_path.exists()})")
                        if potential_path.exists() and potential_path.is_dir() and (potential_path / "config.json").exists():
                            model_path_str = str(potential_path)
                            ic(f"âœ… ëª¨ë¸ ê²½ë¡œ ë°œê²¬ (ai.aiion.site): {model_path_str}")
                        else:
                            ic(f"âš ï¸ ë¡œì»¬ ëª¨ë¸ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path_str}")
                            ic(f"   - Docker: {docker_path}")
                            ic(f"   - ê³µí†µ ì €ì¥ì†Œ: {common_model_path}")
                            ic(f"   - app/{model_path_str}: {app_dir / model_path_str}")
                            ic(f"   - ai.aiion.site/{model_path_str}: {ai_dir / model_path_str}")
        
        model_path = Path(model_path_str)
        is_local_model = model_path.exists() and model_path.is_dir() and (model_path / "config.json").exists()
        
        # ëª¨ë¸ ê²½ë¡œ ì €ì¥ (ë‚˜ì¤‘ì— create_modelì—ì„œ ì‚¬ìš©)
        self.model_path = model_path_str if is_local_model else self.model_name
        
        if is_local_model:
            # ë¡œì»¬ ëª¨ë¸ì˜ í† í¬ë‚˜ì´ì € ë¡œë“œ
            ic(f"âœ… ë¡œì»¬ í† í¬ë‚˜ì´ì € ë¡œë“œ: {model_path}")
            self.tokenizer = AutoTokenizer.from_pretrained(str(model_path))
        else:
            # HuggingFace í† í¬ë‚˜ì´ì € ë¡œë“œ
            ic(f"ğŸŒ HuggingFace í† í¬ë‚˜ì´ì € ë¡œë“œ: {self.model_name}")
            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
        
        # ëª¨ë¸ ì´ˆê¸°í™” (ë‚˜ì¤‘ì— ë¡œë“œ ë˜ëŠ” í•™ìŠµ)
        self.model = None
        
        ic(f"DiaryEmotionDLModel ì´ˆê¸°í™” ì™„ë£Œ: device={self.device}")
    
    def create_model(
        self,
        dropout_rate: float = 0.3,
        hidden_size: Optional[int] = None
    ):
        """
        ëª¨ë¸ ìƒì„±
        
        Args:
            dropout_rate: Dropout ë¹„ìœ¨
            hidden_size: ì¤‘ê°„ hidden layer í¬ê¸°
        """
        # ì €ì¥ëœ ëª¨ë¸ ê²½ë¡œ ì‚¬ìš© (ë¡œì»¬ ëª¨ë¸ì¸ ê²½ìš°)
        model_name_to_use = getattr(self, 'model_path', self.model_name)
        self.model = BERTEmotionClassifier(
            model_name=model_name_to_use,
            num_labels=self.num_labels,
            dropout_rate=dropout_rate,
            hidden_size=hidden_size
        )
        self.model.to(self.device)
        ic(f"ëª¨ë¸ ìƒì„± ì™„ë£Œ: {model_name_to_use}")
    
    def __repr__(self) -> str:
        """ë¬¸ìì—´ í‘œí˜„"""
        return f"DiaryEmotionDLModel(model_name={self.model_name}, device={self.device})"

